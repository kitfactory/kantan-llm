# kantan-llm ğŸ˜ºâœ¨

ã€ŒLLMå‘¼ã¶ãŸã³ã«æ¯å›æ›¸ãã‚„ã¤ï¼ˆã‚­ãƒ¼/URL/ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼åˆ¤å®šï¼‰ã€ã‚’æ¶ˆã—ã¦ã€`get_llm()` ä¸€ç™ºã§å‘¼ã¹ã‚‹è–„ã„Pythonãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã™ã€‚

**ãƒã‚¤ãƒ³ãƒˆ:** ã„ã‚ã‚“ãªãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼/ãƒ¢ãƒ‡ãƒ«ã®ç’°å¢ƒå¤‰æ•°ã‚’ã‚ã‚‰ã‹ã˜ã‚è¨­å®šã—ã¦ãŠã‘ã°ã€ã‚ã¨ã¯ `get_llm("model-name")` ã™ã‚‹ã ã‘ã§ â€œã„ã„æ„Ÿã˜â€ ã«ç¹‹ãŒã‚Šã¾ã™ ğŸ˜ºâœ¨

## æ›´æ–°å†…å®¹ï¼ˆv0.1.7ï¼‰

- Asyncå°ç·šï¼ˆ`get_async_llm` / `get_async_llm_client`ï¼‰ã‚’è¿½åŠ 
- KantanAsyncLLM ã® streaming API ã¨ã¾ã¨ã‚ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’è¿½åŠ 
- Streaming å‡ºåŠ›ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯é †åºï¼ˆ`output_text` â†’ delta â†’ `output_item`ï¼‰ã‚’æ˜ç¢ºåŒ–
- Agents SDK é€£æºã®åˆ©ç”¨æ–¹é‡ã‚’æ•´ç†

## å¯¾å¿œãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ï¼ˆã–ã£ãã‚Šï¼‰ğŸŒ

- OpenAIï¼ˆResponsesï¼‰
- Anthropicï¼ˆClaude / OpenAIäº’æ›SDKï¼‰
- OpenRouterï¼ˆOpenAIäº’æ›Chatï¼‰
- Googleï¼ˆGemini / OpenAIäº’æ›Chatï¼‰
- LMStudio / Ollama / ä»»æ„ã®OpenAIäº’æ›ï¼ˆChatï¼‰

## ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« ğŸ“¦

```bash
pip install kantan-llm
```

## ã¾ãšã¯æœ€çŸ­ã§å‹•ã‹ã™ ğŸš€

### OpenAIï¼ˆResponses API ãŒæ­£æœ¬ï¼‰

```bash
export OPENAI_API_KEY="sk-..."
```

```python
from kantan_llm import get_llm

llm = get_llm("gpt-4.1-mini")
res = llm.responses.create(input="ã“ã‚“ã«ã¡ã¯ã€‚1è¡Œã§è‡ªå·±ç´¹ä»‹ã—ã¦ã€‚")
print(res.output_text)
```

`llm` ã¯ OpenAI SDK äº’æ›ã§ã€æœªå®šç¾©å±æ€§ã¯å†…éƒ¨ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¸å§”è­²ã•ã‚Œã¾ã™ã€‚

### OpenAIäº’æ›ï¼ˆChat Completions ãŒæ­£æœ¬ï¼‰

#### LMStudioï¼ˆä¾‹: `openai/gpt-oss-20b`ï¼‰

```bash
export LMSTUDIO_BASE_URL="http://192.168.11.16:1234"  # /v1 ã¯çœç•¥OK
```

```python
from kantan_llm import get_llm

llm = get_llm("openai/gpt-oss-20b", provider="lmstudio")
cc = llm.chat.completions.create(messages=[{"role": "user", "content": "Return exactly: OK"}], max_tokens=16)
print(cc.choices[0].message.content)
```

#### Ollamaï¼ˆä¾‹ï¼‰

```bash
export OLLAMA_BASE_URL="http://localhost:11434"  # /v1 ã¯çœç•¥OK
```

```python
from kantan_llm import get_llm

llm = get_llm("llama3.2", provider="ollama")
cc = llm.chat.completions.create(messages=[{"role": "user", "content": "Return exactly: OK"}], max_tokens=16)
print(cc.choices[0].message.content)
```

#### Anthropicï¼ˆClaude / OpenAIäº’æ›SDKï¼‰

```bash
export CLAUDE_API_KEY="sk-ant-..."
```

```python
from kantan_llm import get_llm

llm = get_llm("claude-3-5-sonnet-latest")  # `CLAUDE_API_KEY` ãŒã‚ã‚Œã° provider=anthropicï¼ˆæ¨æ¸¬ï¼‰
cc = llm.chat.completions.create(messages=[{"role": "user", "content": "Return exactly: OK"}], max_tokens=16)
print(cc.choices[0].message.content)
```

#### OpenRouterï¼ˆClaudeç­‰ã‚’å«ã‚€ï¼‰

```bash
export OPENROUTER_API_KEY="..."
```

```python
from kantan_llm import get_llm

llm = get_llm("anthropic/claude-3.5-sonnet", provider="openrouter")  # Anthropicå„ªå…ˆã®ãŸã‚OpenRouterã¯æ˜ç¤ºæ¨å¥¨
cc = llm.chat.completions.create(messages=[{"role": "user", "content": "Return exactly: OK"}], max_tokens=16)
print(cc.choices[0].message.content)
```

#### Googleï¼ˆGemini / OpenAIäº’æ›ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆæ‰±ã„ï¼‰

```bash
export GOOGLE_API_KEY="..."
```

```python
from kantan_llm import get_llm

llm = get_llm("gemini-2.0-flash")
cc = llm.chat.completions.create(messages=[{"role": "user", "content": "Return exactly: OK"}], max_tokens=16)
print(cc.choices[0].message.content)
```

## ä½¿ã„åˆ†ã‘ãƒ«ãƒ¼ãƒ« ğŸ§­

- `gpt-oss-*` â†’ å›ºå®šæ¨æ¸¬ã—ãªã„ï¼ˆç’°å¢ƒå¤‰æ•°ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã€‚å¿…è¦ãªã‚‰ `provider=` æŒ‡å®šï¼‰
- `gpt-*`ï¼ˆ`gpt-oss-*` ã‚’é™¤ãï¼‰ â†’ `openai`
- `gemini-*` â†’ `google`
- `claude-*` â†’ `anthropic`ï¼ˆ`CLAUDE_API_KEY` ãŒã‚ã‚‹å ´åˆï¼‰â†’ `openrouter`ï¼ˆ`OPENROUTER_API_KEY` ãŒã‚ã‚‹å ´åˆï¼‰â†’ ãã‚Œä»¥å¤–ã¯ `compat`
- æ¨æ¸¬ã§ããªã„ãƒ¢ãƒ‡ãƒ«åã¯ã€ç’°å¢ƒå¤‰æ•°ãŒã‚ã‚‹ã‚‚ã®ã‚’å„ªå…ˆé †ã§é¸ã³ã¾ã™: `lmstudio` â†’ `ollama` â†’ `openrouter` â†’ `anthropic` â†’ `google`

## æ˜ç¤ºæŒ‡å®šï¼ˆä¸Šæ›¸ãï¼‰ğŸ¯

```python
from kantan_llm import get_llm

llm = get_llm("gpt-4.1-mini", provider="openai")
```

## ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆé †ç•ªãŒå„ªå…ˆåº¦ï¼‰ğŸ§¯

```python
from kantan_llm import get_llm

llm = get_llm("gpt-4.1-mini", providers=["openai", "lmstudio", "openrouter"])
```

## Tracing / Tracer ğŸ§µ

ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã€`get_llm()` ã¯ LLM å‘¼ã³å‡ºã—ã®å…¥åŠ›/å‡ºåŠ›ã‚’è‰²åˆ†ã‘è¡¨ç¤ºã™ã‚‹ç°¡æ˜“ãƒˆãƒ¬ãƒ¼ã‚µãƒ¼ï¼ˆPrintTracerï¼‰ã‚’æœ‰åŠ¹ã«ã—ã¾ã™ã€‚

```python
from kantan_llm import get_llm
from kantan_llm.tracing import trace

llm = get_llm("gpt-4.1-mini")
with trace("workflow"):
    llm.responses.create(input="ã“ã‚“ã«ã¡ã¯ã€‚1è¡Œã§æŒ¨æ‹¶ã—ã¦ã€‚")
```

è©³ã—ã: `docs/tracing.md`

## Asyncï¼ˆASGIå¯¾å¿œï¼‰
ASGIï¼ˆFastAPI/Starletteï¼‰ã§ event loop ã‚’ãƒ–ãƒ­ãƒƒã‚¯ã—ãªã„ãŸã‚ã€async å°ç·šã‚’æä¾›ã—ã¾ã™ã€‚

### get_async_llm()ï¼ˆæ¨å¥¨ï¼‰
- kantan-llm ã®ä¿è¨¼ï¼ˆæ­£è¦åŒ–/ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯/ã‚¬ãƒ¼ãƒ‰/ãƒˆãƒ¬ãƒ¼ã‚¹ï¼‰ã‚’ async ã§ã‚‚ç¶­æŒã—ã¾ã™ã€‚

### Async streamingï¼ˆKantanAsyncLLMï¼‰
KantanAsyncLLM ã§ã¯ streaming API ã‚’æä¾›ã—ã€æœ€çµ‚å¿œç­”ã§ã¾ã¨ã‚ã¦ãƒˆãƒ¬ãƒ¼ã‚¹ã—ã¾ã™ã€‚

```python
from kantan_llm import get_async_llm

llm = get_async_llm("gpt-4.1-mini")
async with llm.responses.stream(input="1è¡Œã§æŒ¨æ‹¶ã—ã¦ã€‚") as stream:
    async for _ in stream:
        pass
    final = await stream.get_final_response()
print(final.output_text)
```

æ³¨æ„:
- å‡ºåŠ›ã®å–å¾—é †åºã¯ `output_text` â†’ ã‚¹ãƒˆãƒªãƒ¼ãƒ å·®åˆ† â†’ `output_item` ã®é †ã§ã™ã€‚
- ã„ãšã‚Œã‚‚ç„¡ã„å ´åˆã¯ã€ã‚¹ãƒˆãƒªãƒ¼ãƒ ã¯å®Œäº†ã—ã¦ã‚‚ãƒˆãƒ¬ãƒ¼ã‚¹ã® output ã¯ç©ºã«ãªã‚Šã¾ã™ï¼ˆä¾‹: `gpt-5-mini`ï¼‰ã€‚

### get_async_llm_client()ï¼ˆEscape hatchï¼‰
- `AsyncOpenAI` ã® raw client ã‚’è¿”ã—ã¾ã™ï¼ˆäº’æ›æ€§æœ€å¤§åŒ–ã€Agents SDK æ³¨å…¥å‘ã‘ï¼‰ã€‚
- **æ³¨æ„:** raw client è¿”å´ã§ã¯ API ã‚¬ãƒ¼ãƒ‰ / è‡ªå‹•ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã¯è¡Œã„ã¾ã›ã‚“ã€‚
- ä»£ã‚ã‚Šã« `model/provider/base_url` ã‚’å«ã‚€ bundle ã‚’è¿”ã—ã€æ­£è¦åŒ–æ¸ˆã¿ model åã‚’ä¸‹æµã¸æ¸¡ã›ã¾ã™ã€‚

## OpenAI Agents SDK é€£æº
Agents SDK ã¯ AsyncOpenAI client ã‚’å·®ã—æ›¿ãˆå¯èƒ½ã§ã™ã€‚

- ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ client ã‚’å·®ã—æ›¿ãˆã‚‹:
  - `set_default_openai_client(AsyncOpenAI(...))`
- ãƒ¢ãƒ‡ãƒ«å˜ä½ã§ client ã‚’æ¸¡ã™:
  - `OpenAIResponsesModel(..., openai_client=AsyncOpenAI(...))`

kantan-agents ã§ã¯ä¸Šè¨˜ 2 ã¤ã®ãƒ¡ã‚½ãƒƒãƒ‰ã‚’åˆ©ç”¨ã—ã¦ client ã‚’å·®ã—æ›¿ãˆã¾ã™ã€‚

kantan-llm ã§ Agents SDK ã‚’ä½¿ã†å ´åˆã®æ¨å¥¨:

- äº’æ›æ€§å„ªå…ˆ: `bundle = get_async_llm_client(...)`
  - `bundle.client` ã‚’ Agents SDK ã«æ¸¡ã™
  - `bundle.model`ï¼ˆæ­£è¦åŒ–æ¸ˆã¿ï¼‰ã‚’ Agent/Model å´ã¸æ¸¡ã™
- kantan ã®ã‚¬ãƒ¼ãƒ‰/ãƒˆãƒ¬ãƒ¼ã‚¹ã‚‚ä½¿ã„ãŸã„: `llm = get_async_llm(...)`
  - ãŸã ã— Agents SDK å´ã¨äºŒé‡ãƒˆãƒ¬ãƒ¼ã‚¹ã«ãªã‚Šå¾—ã‚‹ãŸã‚ã€ã©ã¡ã‚‰ã§ãƒˆãƒ¬ãƒ¼ã‚¹ã™ã‚‹ã‹æ–¹é‡ã‚’æ±ºã‚ã‚‹ï¼ˆä¸‹è¨˜ï¼‰ã€‚

### Tracingï¼ˆäºŒé‡è¨ˆæ¸¬ã‚’é¿ã‘ã‚‹ï¼‰
Agents SDK å´ã«ã¯ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ç„¡åŠ¹åŒ–ã®å°ç·šãŒã‚ã‚Šã¾ã™ï¼ˆä¾‹: `set_tracing_disabled(True)` ã‚„ç’°å¢ƒå¤‰æ•°ï¼‰ã€‚
é‹ç”¨ã§ã¯ä»¥ä¸‹ã®ã©ã¡ã‚‰ã‹ã‚’é¸ã³ã¾ã™ã€‚

- A) Agents SDK ã®ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’æœ‰åŠ¹ã€kantan å´ãƒˆãƒ¬ãƒ¼ã‚¹ã¯ç„¡åŠ¹ï¼ˆã¾ãŸã¯ raw client ã‚’ä½¿ã†ï¼‰
- B) kantan ã®ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’æœ‰åŠ¹ã€Agents SDK å´ãƒˆãƒ¬ãƒ¼ã‚¹ã¯ç„¡åŠ¹

## æ¤œç´¢ï¼ˆSQLiteï¼‰ğŸ”

`SQLiteTracer` ã‚’ä½¿ã†ã¨ã€Trace/Span ã‚’è»½é‡ã«æ¤œç´¢ã§ãã¾ã™ã€‚

```python
from kantan_llm.tracing import SpanQuery, TraceQuery
from kantan_llm.tracing.processors import SQLiteTracer

tracer = SQLiteTracer("traces.sqlite3")
traces = tracer.search_traces(query=TraceQuery(keywords=["hello"], limit=10))
spans = tracer.search_spans(query=SpanQuery(keywords=["hello"], limit=10))
```

è©³ã—ã: `docs/search.md`
ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«: `docs/tutorial_trace_analysis.md`

## Examples / ã‚µãƒ³ãƒ—ãƒ« ğŸ“š

- `examples/tracing_basic.py`
- `examples/search_sqlite.py`

## ç’°å¢ƒå¤‰æ•° ğŸ”

- OpenAI
  - `OPENAI_API_KEY`ï¼ˆå¿…é ˆï¼‰
  - `OPENAI_BASE_URL`ï¼ˆä»»æ„ï¼‰
- Genericäº’æ›ï¼ˆ`compat`ï¼‰
  - `KANTAN_LLM_BASE_URL`ï¼ˆå¿…é ˆï¼‰
  - `KANTAN_LLM_API_KEY`ï¼ˆä»»æ„ï¼šæœªè¨­å®šãªã‚‰ãƒ€ãƒŸãƒ¼å€¤ã‚’ä½¿ã†ï¼‰
- LMStudio
  - `LMSTUDIO_BASE_URL`ï¼ˆå¿…é ˆï¼‰
- Ollama
  - `OLLAMA_BASE_URL`ï¼ˆå¿…é ˆï¼‰
- OpenRouter
  - `OPENROUTER_API_KEY`ï¼ˆå¿…é ˆï¼‰
- Anthropic
  - `CLAUDE_API_KEY`ï¼ˆå¿…é ˆï¼‰
  - `CLAUDE_BASE_URL`ï¼ˆä»»æ„ï¼‰
- Google
  - `GOOGLE_API_KEY`ï¼ˆå¿…é ˆï¼‰
  - `GOOGLE_BASE_URL`ï¼ˆä»»æ„ï¼‰

## ã‚¨ãƒ©ãƒ¼ä¾‹ ğŸ§¨

- å¤±æ•—ï¼ˆOpenAIã‚­ãƒ¼ä¸è¶³ï¼‰: `python -c 'from kantan_llm import get_llm; get_llm(\"gpt-4.1-mini\")'` â†’ `[kantan-llm][E2] Missing OPENAI_API_KEY for provider: openai`

## ãƒ†ã‚¹ãƒˆ ğŸ§ª

ãƒ©ã‚¤ãƒ–çµ±åˆãƒ†ã‚¹ãƒˆï¼ˆå®ŸAPIï¼‰ã¯ã‚ªãƒ—ãƒˆã‚¤ãƒ³ã§ã™:

```bash
KANTAN_LLM_RUN_LIVE_TESTS=1 pytest -q -m integration
```
